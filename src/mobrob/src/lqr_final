#!/usr/bin/env python3

import numpy as np
import math
import matplotlib.pyplot as plt
from kinematics import *
from sensors import *
from utils import *
from time import sleep
import rospy
import serial
import traceback 
from mobrob_util import msg
from std_msgs.msg import Float32,Float32MultiArray
from mobrob_util.msg import ME439SensorsProcessed,ME439WheelSpeeds, ME439WheelDisplacements, IMU
from geometry_msgs.msg import Twist, Pose2D

show_animation = True

wheel_width = rospy.get_param('/wheel_width_model')

class LQR():
    def __init__(self):
        rospy.init_node('lqr_node', anonymous=False)
        self.vel_pub = rospy.Publisher('/wheel_speeds_desired', ME439WheelSpeeds, queue_size=1)
        self.vel = ME439WheelSpeeds()
        
        """######################################################################"""        
        # self.error_pub = rospy.Publisher('/total_error', Float32, queue_size=1)
        # self.error = Float32()

        # self.actual_state_pub = rospy.Publisher('/actual_state', Float32MultiArray, queue_size=1)
        # self.actual_state_msg = Float32MultiArray()

        # self.desired_state_pub = rospy.Publisher('/desired_state', Float32MultiArray, queue_size=1)
        # self.desired_state_msg = Float32MultiArray()

        """######################################################################"""
        self.state_sub = rospy.Subscriber('/robot_pose_estimated', Pose2D, self.state_sub_callback)  
        self.actual_state_x = np.array([0,0,0])


    def state_sub_callback(self, msg):
        self.x_actual = msg.x
        self.y_actual = msg.y
        self.yaw_actual = msg.theta+(np.pi/2)
        self.loop()

    def state_space_model(self,A, state_t_minus_1, B, control_input_t_minus_1):
        """
        Calculates the state at time t given the state at time t-1 and
        the control inputs applied at time t-1
        
        :param: A   The A state transition matrix
            3x3 NumPy Array
        :param: state_t_minus_1     The state at time t-1  
            3x1 NumPy Array given the state is [x,y,yaw angle] ---> 
            [meters, meters, radians]
        :param: B   The B state transition matrix
            3x2 NumPy Array
        :param: control_input_t_minus_1     Optimal control inputs at time t-1  
            2x1 NumPy Array given the control input vector is 
            [linear velocity of the car, angular velocity of the car]
            [meters per second, radians per second]
            
        :return: State estimate at time t
            3x1 NumPy Array given the state is [x,y,yaw angle] --->
            [meters, meters, radians]
        """
        # These next 6 lines of code which place limits on the angular and linear 
        # velocities of the robot car can be removed if you desire.
        control_input_t_minus_1[0] = np.clip(control_input_t_minus_1[0],-max_linear_velocity,max_linear_velocity)
        control_input_t_minus_1[1] = np.clip(control_input_t_minus_1[1],-max_angular_velocity,max_angular_velocity)
        state_estimate_t = (A @ state_t_minus_1) + (B @ control_input_t_minus_1) 
                
        return state_estimate_t

    def closed_loop_prediction(self, desired_traj):
        ## Simulation Parameters
        T = desired_traj.shape[0]  # Maximum simulation time
        goal_dis = 0.1 # How close we need to get to the goal
        goal = desired_traj[-1,:] # Coordinates of the goal
        dt = 0.1 # Timestep interval
        time = 0.0 # Starting time
    
        ## Initial States 
        self.state = np.array([8.3,0.69,0]) # Initial state of the car
        self.state_est = self.state.copy()
        yaw = self.state[2]
        Q = np.array([  [1.0, 0, 0],  # Penalize X position error 
                        [0, 1.0, 0],  # Penalize Y position error 
                        [0, 0, 1.0]]) # Penalize YAW ANGLE heading error 
    
        R = np.array([  [0.1,   0],  # Penalty for linear velocity effort
                        [  0, 0.1]]) # Penalty for angular velocity effort
    
        A = np.array([  [1.0,  0,   0],
                        [  0,1.0,   0],
                        [  0,  0, 1.0]])

        B = np.array([  [np.cos(yaw)*dt, 0],
                        [np.sin(yaw)*dt, 0],
                        [0            , dt]])
        ## Create objects for storing states and estimated state
        self.t = [self.time]
        self.traj = np.array([self.state])
        self.traj_est = np.array([self.state_est])
    
        ind = 0
        while T >= time:
            
            ## Point to track
            ind = int(np.floor(time))
            goal_i = desired_traj[ind,:]
    
            ## Generate optimal control commands
            u_lqr = self.dLQR(Q,R,self.state_est,goal_i[0:3],dt)
    
            ## Move forwad in time
            state = DiffDrive.forward(state,u_lqr,v,dt)
        
            time = time + dt

            v_c = u_lqr[0]
            omega = u_lqr[1]
            
            self.vel.v_left = (2*v_c-omega*wheel_width)/2
            self.vel.v_right = v_c+(omega*wheel_width)/2
            
            # We apply the optimal control to the robot
            # so we can get a new actual (estimated) state.
            self.actual_state_x = self.state_space_model(A, self.actual_state_x, B, 
                                            u_lqr)  
            if state_error_magnitude < 0.1:
                self.vel.v_left = 0.0
                self.vel.v_right = 0.0
                # Stop as soon as we reach the goal
                # Feel free to change this threshold value.
                # if state_error_magnitude < 0.01:
                #     print("\nGoal Has Been Reached Successfully!")
                #     break
            self.vel.v_left = np.clip(self.vel.v_left,-0.2,0.3)                    
            self.vel.v_right = np.clip(self.vel.v_right,-0.2,0.3)                    

                #print()
            self.actual_state_msg.data = self.actual_state_x
            self.actual_state_pub.publish(self.actual_state_msg)

            self.desired_state_msg.data = desired_state_xf
            self.desired_state_pub.publish(self.desired_state_msg)

            self.vel_pub.publish(self.vel)
            self.error_pub.publish(state_error_magnitude)
    
            # Store the trajectory and estimated trajectory
            t.append(time)
            traj = np.concatenate((traj,[state]),axis=0)
            traj_est = np.concatenate((traj_est,[state_est]),axis=0)
    
            # Check to see if the robot reached goal
            if np.linalg.norm(state[0:2]-goal[0:2]) <= goal_dis:
                print("Goal reached")
                break
    
            ## Plot the vehicles trajectory
            if time % 1 < 0.1 and show_animation:
                plt.cla()
                plt.plot(desired_traj[:,0], desired_traj[:,1], "-r", label="course")
                plt.plot(traj[:,0], traj[:,1], "ob", label="trajectory")
                plt.plot(traj_est[:,0], traj_est[:,1], "sk", label="estimated trajectory")
    
                plt.plot(goal_i[0], goal_i[1], "xg", label="target")
                plt.axis("equal")
                plt.grid(True)
                plt.title("SINGAPORE GRAND PRIX\n" + "speed[m/s]:" + str(
                                                round(np.mean(u_lqr), 2)) +
                        ",target index:" + str(ind))
                plt.pause(0.0001)
    
            #input()
    
        return t, traj

    def linearize(self, x, dt=0.1):
        """
        Creates a linearized version of the dynamics of the differential 
        drive robotic system (i.e. a
        robotic car where each wheel is controlled separately.
    
        The system's forward kinematics are nonlinear due to the sines and 
        cosines, so we need to linearize 
        it by taking the Jacobian of the forward kinematics equations with respect 
        to the control inputs.
    
        Our goal is to have a discrete time system of the following form: 
        x_t+1 = Ax_t + Bu_t where:
    
        Input
        :param x: The state of the system (units:[m,m,rad]) -> 
                    np.array with shape (3,) ->
                    (X, Y, THETA) ->
                    X_system = [x1, x2, x3]
        :param dt: The change in time from time step t to time step t+1      
    
        Output
        :return: A: Matrix A is a 3x3 matrix (because there are 3 states) that 
                    describes how the state of the system changes from t to t+1 
                    when no control command is executed. Typically, 
                    a robotic car only drives when the wheels are turning. 
                    Therefore, in this case, A is the identity matrix.
        :return: B: Matrix B is a 3 x 2 matrix (because there are 3 states and 
                    2 control inputs) that describes how
                    the state (X, Y, and THETA) changes from t to t + 1 due to 
                    the control command u.
                    Matrix B is found by taking the The Jacobian of the three 
                    forward kinematics equations (for X, Y, THETA) 
                    with respect to u (3 x 2 matrix)
    
        """
        THETA = x[2]
    
        ####### A Matrix #######
        # A matrix is the identity matrix
        A = np.array([[1.0,   0,  0],
                    [  0, 1.0,  0],
                    [  0,   0, 1.0]])
    
        ####### B Matrix #######
        B = np.array([[np.cos(THETA)*dt, 0],
                    [np.sin(THETA)*dt, 0],
                    [0, dt]])
            
        return A, B

    def dLQR(self,Q,R,x,xf,dt=0.1):
        """
        Discrete-time linear quadratic regulator for a non-linear system.
    
        Compute the optimal control given a nonlinear system, cost matrices, 
        a current state, and a final state.
        Compute the control variables that minimize the cumulative cost.
    
        Solve for P using the dynamic programming method.
    
        Assume that Qf = Q
    
        Input:
        :param F: The dynamics class object (has forward and linearize functions 
                    implemented)
        :param Q: The state cost matrix Q -> np.array with shape (3,3)
        :param R: The input cost matrix R -> np.array with shape (2,2)
        :param x: The current state of the system x -> np.array with shape (3,)
        :param xf: The desired state of the system xf -> np.array with shape (3,)
        :param dt: The size of the timestep -> float
    
        Output
        :return: u_t_star: Optimal action u for the current state 
                    [linear velocity of the car, angular velocity of the car]
                    [meters per second, radians per second]
        """
        # We want the system to stabilize at xf, 
        # so we let x - xf be the state.
        # Actual state - desired state
        x_error = x - xf
    
        # Calculate the A and B matrices
        A, B = self.linearize(x, dt)
    
        # Solutions to discrete LQR problems are obtained using dynamic 
        # programming.
        # The optimal solution is obtained recursively, starting at the last 
        # time step and working backwards.
        N = 50
    
        # Create a list of N + 1 elements
        P = [None] * (N + 1)
    
        # Assume Qf = Q
        Qf = Q
    
        # 1. LQR via Dynamic Programming 
        P[N] = Qf 
    
        # 2. For t = N, ..., 1
        for t in range(N, 0, -1):
    
        # Discrete-time Algebraic Riccati equation to calculate the optimal 
        # state cost matrix
            P[t-1] = Q + A.T @ P[t] @ A - (A.T @ P[t] @ B) @ la.pinv(
                R + B.T @ P[t] @ B) @ (B.T @ P[t] @ A)      
    
        # Create a list of N elements
        K = [None] * N
        u = [None] * N
    
        # 3 and 4. For t = 0, ..., N - 1
        for t in range(N):
    
        # Calculate the optimal feedback gain K_t
            K[t] = -la.pinv(R + B.T @ P[t+1] @ B) @ B.T @ P[t+1] @ A
    
        for t in range(N):
        
        # Calculate the optimal control input
            u[t] = K[t] @ x_error
    
        # Optimal control input is u_t_star
        u_t_star = u[N-1]
    
        # Return the optimal control inputs
        return u_t_star

    def main(self):
     
        # Countdown to start
        print("\n*** SINGAPORE GRAND PRIX ***\n")
        print("Start your engines!")
        print("3.0")
        sleep(1.0)
        print("2.0")
        sleep(1.0)
        print("1.0\n")
        sleep(1.0)
        print("LQR + EKF steering control tracking start!!")
    
        # Create the track waypoints
        ax = [8.3,8.0, 7.2, 6.5, 6.2, 6.5, 1.5,-2.0,-3.5,-5.0,-7.9,
        -6.7,-6.7,-5.2,-3.2,-1.2, 0.0, 0.2, 2.5, 2.8, 4.4, 4.5, 7.8, 8.5, 8.3]
        ay = [0.7,4.3, 4.5, 5.2, 4.0, 0.7, 1.3, 3.3, 1.5, 3.0,-1.0,
        -2.0,-3.0,-4.5, 1.1,-0.7,-1.0,-2.0,-2.2,-1.2,-1.5,-2.4,-2.7,-1.7,-0.1]
        
        # These landmarks help the mobile robot localize itself
        landmarks = [[4,3],
                    [8,2],
                    [-1,-4]]
            
        # Compute the desired trajectory
        desired_traj = compute_traj(ax,ay)
    
        t, traj = self.closed_loop_prediction(desired_traj,landmarks)
 
        # Display the trajectory that the mobile robot executed
        if show_animation:
            plt.close()
            flg, _ = plt.subplots(1)
            plt.plot(ax, ay, "xb", label="input")
            plt.plot(desired_traj[:,0], desired_traj[:,1], "-r", label="spline")
            plt.plot(traj[:,0], traj[:,1], "-g", label="tracking")
            plt.grid(True)
            plt.axis("equal")
            plt.xlabel("x[m]")
            plt.ylabel("y[m]")
            plt.legend()
    
            plt.show()


    

# Entry point for the program
if __name__ == "__main__":
    try:
        # Optional Variables    
        max_linear_velocity = .4 # meters per second
        max_angular_velocity = 1.5708 # radians per second
        lqr = LQR()
        rospy.spin()

    except rospy.ROSInterruptException: 
        lqr.v_left = 0.0
        lqr.v_right = 0.0
        lqr.vel_pub.publish(lqr.vel)
        rospy.loginfo("LQR node terminated.")    
        pass

